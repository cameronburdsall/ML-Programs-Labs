{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvFkYhe5a4rL"
      },
      "source": [
        "#Lab 4\n",
        "Cameron Burdsall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efkAdlphoiVN"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math, random\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHvpUSpeo0WD"
      },
      "source": [
        "# training set\n",
        "train_df = pd.read_csv(\n",
        "    filepath_or_buffer='http://www.cse.scu.edu/~yfang/coen140/crime-train.txt', sep='\\t') #tab separated\n",
        "# test set\n",
        "test_df = pd.read_csv(\n",
        "    filepath_or_buffer='http://www.cse.scu.edu/~yfang/coen140/crime-test.txt', sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbY3Y00No2G3"
      },
      "source": [
        "# Preprocess data by arranging columns\n",
        "\n",
        "#declare matrix X and insert Column of 1's into the data frame\n",
        "df = train_df\n",
        "train_df.T\n",
        "#take target column\n",
        "y_column = 'ViolentCrimesPerPop'\n",
        "y = df[y_column]\n",
        "\n",
        "#create a copy of the df, drop the y col, and add a col full of 1's\n",
        "X = df.copy()\n",
        "X = X.drop(y_column, axis = 1)\n",
        "X.insert(0, 'ones', 1)\n",
        "\n",
        "#create testing datasets\n",
        "df = test_df\n",
        "y_test = df[y_column]\n",
        "X_test = df.copy()\n",
        "X_test = X_test.drop(y_column, axis = 1)\n",
        "X_test.insert(0, 'ones', 1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WagKaRJo5Ke"
      },
      "source": [
        "def RMSE (prediction, result):\n",
        "  # input are two vectors, one holding the generated prediction, one the actual result\n",
        "  # caluclate difference between vectors\n",
        "  dif = prediction - result\n",
        "  tot = 0\n",
        "  # go through and sum the squares of the differences\n",
        "  for num in dif:\n",
        "    tot += num ** 2\n",
        "  return math.sqrt(tot / len(dif))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xma4DH-pQts"
      },
      "source": [
        "#Linear Regression Closed Form\n",
        "Using the closed form property that **b = (X\\`X)^-1(X\\`Y)** where b is the coefficient vector,\n",
        "X is the independent variables matrix, X` is the transpose of X, and Y is the solution vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGajeltRpKHd"
      },
      "source": [
        "def problem1 (train, y_train, predict):\n",
        "  # train variables used to construct model, predict used to set what model is then predicting\n",
        "  # predict theta parameters and return the result of the dot product of the dataset and the betas\n",
        "\n",
        "  # dealing with the left parenthesis in the coefficient equation above\n",
        "  lefthand = np.dot(train.T, train)\n",
        "  lefthand = np.linalg.inv(lefthand)\n",
        "\n",
        "  # dealing with the right parenthesis\n",
        "  righthand = np.dot(train.T, y_train)\n",
        "\n",
        "  #calculate coefficient predictions\n",
        "  betas = np.dot(lefthand, righthand)\n",
        "\n",
        "  # apply betas to all entries in the set which we want to predict\n",
        "  return np.dot(predict, betas)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky1kidzIpZHp",
        "outputId": "17cd5e2d-bf66-4bb7-bd98-950b1b321355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# find RMSE on original set\n",
        "train_prediction = RMSE(problem1(X, y, X), y)\n",
        "print(train_prediction)\n",
        "\n",
        "# find RMSE on testing set\n",
        "test_prediction = RMSE(problem1(X, y, X_test), y_test)\n",
        "print(test_prediction)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12768967421762206\n0.14583464490948847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7SUj8u5vbvJ"
      },
      "source": [
        "def generate_permutation (n):\n",
        "  lst=[]\n",
        "  for i in range(n):\n",
        "    lst.append(i)\n",
        "  random.shuffle(lst)\n",
        "  return lst"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js5JE5bKwoix"
      },
      "source": [
        "#Stochastic Gradient Decent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSMC1ReZdE5",
        "outputId": "81dc5b1c-b888-4d9f-8ac2-90ef29fc43e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def generate_permutation(n):\n",
        "  a = []\n",
        "  for i in range (n):\n",
        "    a.append(i)\n",
        "  a = shuffle(a)\n",
        "  return a\n",
        "def SGD(X, y, nullbias = False, maxit=1e+6, alpha=5e-4, threshold=10e-10):\n",
        "  #default alpha and threshold values are the ones that were found\n",
        "  #to achieve the lowest RMSE scores\n",
        "\n",
        "  #random initial weights\n",
        "  t = np.random.randn(len(X.columns), 1)\n",
        "\n",
        "  #null bias\n",
        "  if nullbias:\n",
        "    t[0] = 0 \n",
        "  new_t = None\n",
        "\n",
        "  #generate initial permutation\n",
        "  #perm = generate_permutation(len(X))\n",
        "  it = 0\n",
        "  sdif = 1\n",
        "\n",
        "  while (abs(sdif) > threshold) and (it < maxit):\n",
        "    # take a step for each sample in a random permutation of the dataset\n",
        "    # reshuffle the permutation when we have gone thru the entire set\n",
        "    # evaluate for theta for each entry in the permutation to find a model using Stochatic Gradient Decent\n",
        "    #for ind in perm:\n",
        "    ind = random.randint(0, len(X) - 1)\n",
        "      #grab samples for this iteration\n",
        "    X_entry = X.iloc[[ind]]\n",
        "    y_entry = y.iloc[[ind]].item()\n",
        "\n",
        "      #formatting due to errors\n",
        "    y_entry = np.asarray(y_entry)\n",
        "    y_entry.reshape(1, 1) \n",
        "\n",
        "      #apply thetas to the entry to yield the estimated value\n",
        "    y_hat = np.dot(X_entry, t)\n",
        "\n",
        "      #calculate the cost\n",
        "    cost = y_entry - y_hat\n",
        "      # (y_hat - y)xi\n",
        "    cost_entry = np.dot(X_entry.T, cost)\n",
        "      #new_theta = theta + (alpha(y_hat - y)xi)\n",
        "    new_t = t + (alpha * cost_entry)\n",
        "      #calculate theta difference to check for convergence\n",
        "    dif = new_t - t\n",
        "    sdif = np.sum(dif)\n",
        "\n",
        "      #delete the comment below to see how the model converges, but this will make the program take MUCH more time to execute due to print overhead\n",
        "      #print(sdif)\n",
        "\n",
        "      #assign new thetas\n",
        "    t = new_t\n",
        "    it += 1\n",
        "      # check for convergence\n",
        "    if (abs(sdif) < threshold):\n",
        "      print('Convergence Reached')\n",
        "      print('Iterations: ' + str(it))\n",
        "      break\n",
        "      # if we reached max iterations\n",
        "    if (maxit <= it):\n",
        "      print('No convergence')\n",
        "      print('Max Iterations Reached: ' + str(int(maxit)))\n",
        "      #return last model if max iterations reached\n",
        "      return t\n",
        "    #perm = shuffle(perm)\n",
        "  #return model generated by SGD\n",
        "  return t\n",
        "\n",
        "model = SGD(X, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3408\u001b[0m         \"\"\"\n\u001b[1;32m-> 3409\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3410\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3394\u001b[1;33m         new_data = self._data.take(\n\u001b[0m\u001b[0;32m   3395\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indices are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-8efedf31bbb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-11-8efedf31bbb4>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(X, y, nullbias, maxit, alpha, threshold)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m       \u001b[1;31m#grab samples for this iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mX_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0my_entry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2127\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2129\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2131\u001b[0m         \u001b[1;31m# a single integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[1;31m# re-raise with different error message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2114\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt0kAp3xusU1",
        "outputId": "90aab768-a549-494b-f10b-4943f00907e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#having alpha be greater than 5e-3 causes the loss score to somehow INCREASE\n",
        "\n",
        "#apply model to the dataset\n",
        "y_pred = np.dot(X, model)\n",
        "y_tes = np.dot(X_test, model)\n",
        "\n",
        "#formatting nonsense\n",
        "t_y = np.asarray(y).reshape(1595, 1)\n",
        "tt_y = np.asarray(y_test).reshape(399, 1)\n",
        "\n",
        "#RMSE scores vary wildly, model generation is not consistent\n",
        "train_RMSESGD = RMSE(y_pred, t_y)\n",
        "print(train_RMSESGD)\n",
        "test_RMSESGD = RMSE(y_tes, tt_y)\n",
        "print(test_RMSESGD)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-affeb04cedc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#apply model to the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_tes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dne7kz340mnn"
      },
      "source": [
        "#Best Stochatic Gradient Model Decent Parameters & Results\n",
        "1.  alpha = 5e-4 <br>\n",
        "    threshold = 10e-10 <br>\n",
        "    Train RMSE: 0.14196462300010157 <br>\n",
        "    Test RMSE: 0.162137795588426 <br>\n",
        "    Iterations: 707865 <br>\n",
        "2.  alpha = 5e-4 <br>\n",
        "    threshold = 10e-10 <br>\n",
        "    Train RMSE: 0.14279185205207573 <br>\n",
        "    Test RMSE: 0.15955539536691501 <br>\n",
        "    Iterations: 834326 <br>\n",
        "3.  alpha = 5e-3 <br>\n",
        "    threshold = 10e-9 <br>\n",
        "    Train RMSE: 0.14445652339078446 <br>\n",
        "    Test RMSE: 0.16299297230777626 <br>\n",
        "    Iterations: 301456 <br>\n",
        "\n",
        " \n",
        "\n",
        "I noticed that typically, more iterations led to a more accurate model, except for the cases where the model gets stuck in local minima. This would occur if the alpha and threshold were set sufficeintly low. The best step values were in the range of 5e-3 to 5e-4. Anything above 5e-3 would overshoot and cause the model generation to get stuck in an infinite loop with the model values jumping around wildly, and anything smaller than 5e-4 would cause the thetas to get stuck in a local minima and not find the global. Generally, the lower the threshold, the better the results, except when the theshold is set too so such that the GD never converges, and oscillates around the minimum infinitely.<br><br>\n",
        "\n",
        "The Closed form solution was able to genearate a more accurate as well as consistent model much faster than using SGD<br>\n"
      ]
    }
  ]
}