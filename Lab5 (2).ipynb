{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhNU96nd5BlJ"
      },
      "source": [
        "#Lab 5\n",
        "Cameron Burdsall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQeiaDA323u8"
      },
      "source": [
        "#files stored on share drive\n",
        "train_filepath = 'spambase/spam-train'\n",
        "test_filepath = 'spambase/spam-train'\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math, random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4m3cs6c3iI7"
      },
      "source": [
        "train_df = pd.read_csv(filepath_or_buffer= train_filepath, header=None)\n",
        "test_df = pd.read_csv(filepath_or_buffer= test_filepath, header=None)\n",
        "\n",
        "assert (len(train_df.columns) == len(test_df.columns))\n",
        "\n",
        "last_col = len(train_df.columns) - 1\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o33LlrK5Hse"
      },
      "source": [
        "#Normalize the dataset columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHy7xny4qeT",
        "outputId": "10e9c087-ca18-4141-d2be-e68c66c91d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#all of these ops are column wise, so we can hit each column as needed\n",
        "norm_train_df = (train_df - train_df.mean())/train_df.std()\n",
        "norm_test_df = (test_df - test_df.mean())/test_df.std()\n",
        "\n",
        "X_train = norm_train_df.drop(last_col, axis = 1)\n",
        "X_test = norm_test_df.drop(last_col, axis = 1)\n",
        "X_train['ones'] = np.ones(X_train.shape[0])\n",
        "X_test['ones'] = np.ones(X_test.shape[0])\n",
        "#ensure proper formatting\n",
        "\n",
        "y_train = train_df[last_col]\n",
        "y_test = test_df[last_col]\n",
        "\n",
        "print(X_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0         1         2         3         4         5         6  \\\n0    -0.341197 -0.167892 -0.559543 -0.047041  0.990915 -0.358135 -0.279760   \n1    -0.341197 -0.167892 -0.559543 -0.047041 -0.450720 -0.358135 -0.279760   \n2    -0.341197  0.259688 -0.559543 -0.047041  1.062283 -0.358135  3.589996   \n3    -0.341197 -0.167892 -0.113615 -0.047041  0.862453 -0.358135 -0.279760   \n4    -0.341197 -0.167892 -0.559543 -0.047041 -0.450720 -0.358135 -0.279760   \n...        ...       ...       ...       ...       ...       ...       ...   \n3060 -0.341197 -0.167892 -0.559543 -0.047041 -0.450720 -0.358135 -0.279760   \n3061 -0.341197 -0.167892 -0.559543 -0.047041  2.346909 -0.358135 -0.279760   \n3062 -0.341197 -0.167892 -0.559543 -0.047041 -0.450720 -0.358135 -0.279760   \n3063  0.707495 -0.167892 -0.559543 -0.047041 -0.450720 -0.358135 -0.279760   \n3064  0.643938 -0.167892  0.642523 -0.047041 -0.450720  0.812828 -0.279760   \n\n             7         8         9  ...        48        49        50  \\\n0    -0.274942 -0.318200 -0.395557  ... -0.160496 -0.219886 -0.164386   \n1    -0.274942 -0.318200 -0.395557  ...  0.244309  2.059477 -0.164386   \n2    -0.274942 -0.318200  0.460440  ... -0.160496  0.467108  0.603462   \n3    -0.274942  0.505942 -0.395557  ... -0.160496 -0.028801  0.088323   \n4    -0.274942 -0.318200 -0.395557  ... -0.160496 -0.620253 -0.164386   \n...        ...       ...       ...  ...       ...       ...       ...   \n3060 -0.274942 -0.318200 -0.395557  ... -0.160496  2.491692 -0.164386   \n3061 -0.274942 -0.318200 -0.395557  ... -0.160496  2.409798 -0.164386   \n3062 -0.274942 -0.318200 -0.395557  ... -0.160496 -0.620253 -0.164386   \n3063 -0.274942 -0.318200 -0.395557  ... -0.160496  0.175932  0.399350   \n3064 -0.274942 -0.318200 -0.395557  ... -0.160496  0.435260 -0.164386   \n\n            51        52        53        54        55        56  ones  \n0    -0.449056  0.028504 -0.099663  0.054088 -0.129557 -0.114247   1.0  \n1    -0.449056 -0.297565 -0.099663 -0.091047 -0.215281 -0.306383   1.0  \n2    -0.169589 -0.297565 -0.099663 -0.013076  0.010717 -0.257958   1.0  \n3    -0.403357 -0.297565 -0.037943 -0.085520 -0.207488  0.299705   1.0  \n4    -0.449056 -0.297565 -0.099663 -0.110175 -0.355555 -0.434474   1.0  \n...        ...       ...       ...       ...       ...       ...   ...  \n3060 -0.449056 -0.297565 -0.099663 -0.119583 -0.371141 -0.436036   1.0  \n3061 -0.449056 -0.297565 -0.099663 -0.088966 -0.332176 -0.420415   1.0  \n3062 -0.449056 -0.297565 -0.099663 -0.082880 -0.324383 -0.403232   1.0  \n3063 -0.245168 -0.297565 -0.099663 -0.115050 -0.347762 -0.332938   1.0  \n3064 -0.449056 -0.297565 -0.099663 -0.119055 -0.363348 -0.312631   1.0  \n\n[3065 rows x 58 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4CUY1qBB1gK"
      },
      "source": [
        "def hypothesis (t, X):\n",
        "  #returns hypothesis of the dataset and thetas by bounding results using sigmoid function\n",
        "  #apply thetas to dataset\n",
        "  # X = nxm * mx1 = nx1\n",
        "  app = np.dot(X, t)\n",
        "  #return sigmoid of theta application\n",
        "  return sigmoid(app)\n",
        "def sigmoid (t):\n",
        "  return np.divide(1, 1 + np.exp(-t))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WagKaRJo5Ke"
      },
      "source": [
        "def RMSE (prediction, result):\n",
        "  # input are two vectors, one holding the generated prediction, one the actual result\n",
        "  # caluclate difference between vectors\n",
        "  dif = prediction - result\n",
        "  tot = 0\n",
        "  # go through and sum the squares of the differences\n",
        "  if len(dif) == 0:\n",
        "    raise Exception(\"Difference Calculation error, check inputs\")\n",
        "  for num in dif:\n",
        "    tot += num ** 2\n",
        "  return math.sqrt(tot / len(dif))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V65i0QOLv-EA"
      },
      "source": [
        "def adjust_results (y_hat):\n",
        "  for i in range(len(y_hat)):\n",
        "    if y_hat[i] >= 0.5:\n",
        "      y_hat[i] = 1\n",
        "    else:\n",
        "      y_hat[i] = 0\n",
        "  return y_hat"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELpwHGz3ty3O",
        "outputId": "0b6c5dec-8bb5-4611-bc23-ca021cee055c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       1.0\n",
            "1       1.0\n",
            "2       1.0\n",
            "3       0.0\n",
            "4       0.0\n",
            "       ... \n",
            "3060    0.0\n",
            "3061    0.0\n",
            "3062    0.0\n",
            "3063    0.0\n",
            "3064    0.0\n",
            "Name: 57, Length: 3065, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp9fRTA9O-4l"
      },
      "source": [
        "def LR_gradient_decent (X, y, nullbias = False,  maxit=1e+6, alpha=5e-5, threshold=10e-5):\n",
        "  x = np.float128(X)\n",
        "  npy = np.float128(y)\n",
        "  n = len(X.columns)\n",
        "  sdif = 1\n",
        "  t = np.random.normal(0, 1, size = n)\n",
        "  it = 0\n",
        "  while (abs(sdif)  > threshold and it < maxit):\n",
        "    #generate hypothesis\n",
        "    y_hat = hypothesis(t, x)\n",
        "    y_hat = adjust_results(y_hat)\n",
        "    #calculate difference from actual\n",
        "    error = y_hat - npy\n",
        "    #cost = (alpha / n) * (error)\n",
        "    #update = np.dot(X.T, cost)\n",
        "\n",
        "    left = np.multiply((alpha/n), x.T)\n",
        "    update = np.dot(left, error)\n",
        "    #for some reason, the sum of the errors only gets bigger, should get SMALLER!!!!!!!!!!!!!\n",
        "    #print(sum(error))\n",
        "    #update thetas\n",
        "    #new_t = t + update\n",
        "    new_t = t - update\n",
        "    #check for convergence\n",
        "    dif = np.linalg.norm(new_t - t)\n",
        "    sdif = np.sum(dif)\n",
        "    print(sdif)\n",
        "    if (abs(sdif) < threshold):\n",
        "      break\n",
        "    t = new_t\n",
        "    it += 1\n",
        "  \n",
        "  if (it >= maxit):\n",
        "    print('No Convergence')\n",
        "    print('Max Iterations Reached: ' + str(maxit))\n",
        "  \n",
        "  else:\n",
        "    print('Convergence')\n",
        "    print('Iterations: ' + str(it))\n",
        "\n",
        "  return t\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqDiNTwwJb8O",
        "outputId": "41ed8961-bddc-478d-95f9-c5e025006c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LR_gradient_decent(X_train, y_train)\n",
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float128'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-e8deb55b451a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLR_gradient_decent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-9-731edb72c87b>\u001b[0m in \u001b[0;36mLR_gradient_decent\u001b[1;34m(X, y, nullbias, maxit, alpha, threshold)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mLR_gradient_decent\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnullbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmaxit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e+6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat128\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mnpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat128\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0msdif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[0;32m    220\u001b[0m                                      \"{!r}\".format(__name__, attr))\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float128'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-e5Nh2Trrf"
      },
      "source": [
        "train_results = adjust_results(sigmoid(np.dot(X_train, model)))\n",
        "test_results = adjust_results(sigmoid(np.dot(X_test, model)))\n",
        "\n",
        "#train_results = adjust_results(np.dot(X_train, model))\n",
        "#test_results = adjust_results(np.dot(X_test, model))\n",
        "\n",
        "y_tra = np.asarray(y_train).reshape(3065, 1)\n",
        "train_results = np.asarray(train_results).reshape(3065, 1)\n",
        "\n",
        "y_test = np.asarray(y_test).reshape(1536, 1)\n",
        "test_results = np.asarray(test_results).reshape(1536, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArEetvF_JZUN"
      },
      "source": [
        "count1 = 0\n",
        "for i in range (len(y_tra)):\n",
        "  if y_tra[i] != train_results[i]:\n",
        "    count1 += 1\n",
        "print(count1 / len(y_tra))\n",
        "#print(test_results)\n",
        "count2 = 0\n",
        "for i in range (len(y_test)):\n",
        "  if y_test[i] != test_results[i]:\n",
        "    count2 += 1\n",
        "print(count2 / len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR684YRPB115"
      },
      "source": [
        "previous lab for ref"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNtgP3jp-Fwh"
      },
      "source": [
        "def GD(X, y, t0 = False, maxit=1e+6, alpha=5e-5, threshold=10e-11):\n",
        "  #default alpha and threshold values are the ones that were found\n",
        "  #to achieve the lowest RMSE scores\n",
        "\n",
        "  #random initial weights\n",
        "  t = np.random.randn(len(X.columns), 1)\n",
        "\n",
        "  #null bias\n",
        "  if t0:\n",
        "    t[0] = 0 \n",
        "  new_t = None\n",
        "\n",
        "  #generate initial permutation\n",
        "  perm = generate_permutation(len(X))\n",
        "  it = 0\n",
        "  sdif = 1\n",
        "\n",
        "  while (abs(sdif) > threshold) and (it < maxit):\n",
        "    # take a step for each sample in the random permutation of the dataset\n",
        "    # reshuffle the permutation when we have gone thru the entire set\n",
        "    # evaluate for theta for each entry in the permutation\n",
        "    for ind in perm:\n",
        "      #grab samples for this iteration\n",
        "      #iloc[[]] accesses rows\n",
        "      X_entry = X.iloc[[ind]]\n",
        "      y_entry = y.iloc[[ind]].item()\n",
        "\n",
        "      #formatting due to errors\n",
        "      y_entry = np.asarray(y_entry)\n",
        "      y_entry.reshape(1, 1) \n",
        "\n",
        "      #apply thetas to the entry to yield the estimated value\n",
        "      y_hat = np.dot(X_entry, t)\n",
        "\n",
        "      #calculate the cost\n",
        "      cost = y_entry - y_hat\n",
        "      # (y_hat - y)xi\n",
        "      cost_entry = np.dot(X_entry.T, cost)\n",
        "      #new_theta = theta + (alpha(y_hat - y)xi)\n",
        "      new_t = t + (alpha * cost_entry)\n",
        "      #calculate theta difference to check for convergence\n",
        "      dif = new_t - t\n",
        "      sdif = np.sum(dif)\n",
        "      #assign new thetas\n",
        "      t = new_t\n",
        "      it += 1\n",
        "      # check for convergence\n",
        "      if (abs(sdif) < threshold):\n",
        "        print('Convergence Reached')\n",
        "        print('Iterations: ' + str(it))\n",
        "        break\n",
        "      # if we reached max iterations\n",
        "      if (maxit <= it):\n",
        "        print('No convergence')\n",
        "        print('Max Iterations Reached: ' + str(maxit))\n",
        "        #return last model if max iterations reached\n",
        "        return t\n",
        "\n",
        "    perm = shuffle(perm)\n",
        "\n",
        "  #return model generated by SGD\n",
        "  return t\n",
        "\n",
        "model = SGD(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}